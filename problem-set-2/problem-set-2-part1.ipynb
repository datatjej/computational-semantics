{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 - Part 1: Ambiguity and Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the following instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "\n",
    "### Pre-requisite knowledge\n",
    "\n",
    "Understanding of `problem-set-1`:\n",
    "- First order logic\n",
    "- Lambda calculus\n",
    "- Feature unification context free grammar\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Follow the instructions step-by-step.\n",
    "- Run all cells before modifying them to see how the code works.\n",
    "- The tasks will ask you to modify cells in this notebook.\n",
    "- Modify the cell to provide your answer and run a test before submiting the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task requires NLTK and Jupyter Notebook (IPython package).\n",
    "\n",
    "import nltk\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.sem import cooper_storage as cs\n",
    "\n",
    "from utils import display_latex, display_translation, display_tree, display, Markdown\n",
    "from copy import deepcopy\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to import functions and syntax specific to this problem set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils2 import sem_parser, evaluate_sentences, syntax, syntax_notv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Ambiguity in quantifiers [6 marks in total]\n",
    "\n",
    "Follow the descriptions and instructions in sections **(1.1)**, **(1.2)** and **(1.3)** to learn about the code and the examples. Then answer the questions in section **(1.4)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. FCFG with a SEM feature\n",
    "\n",
    "You should already be familar with FCFG with a SEM feature. \n",
    "Use the code below to parse the following sentences to their semantic representations:\n",
    "\n",
    "1. every dog bites a bone\n",
    "2. a man gives a bone to every dog\n",
    "3. Russia gives Moscow to Napoleon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'all dogs bite a bone',\n",
    "    'a man gives a bone to every dog',\n",
    "    'Russia gives Moscow to Napoleon',\n",
    "]\n",
    "\n",
    "# if you want to see the parse tree change `verbose` to True:\n",
    "sents_reps = sem_parser(sentences, syntax, verbose=False)\n",
    "\n",
    "for i, (sent, semreps) in enumerate(sents_reps.items()):\n",
    "    for semrep in semreps:\n",
    "        display_translation(f\"{i+1}. {sent}\", semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. Evaluate sentences in a model\n",
    "\n",
    "We have a world model with entities and sets to represent their properties and relationships. \n",
    "Run the code below to evaluate the sentence representations from the previous section in the world model defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a world model:\n",
    "entities = \"\"\"\n",
    "russia    => c1\n",
    "moscow    => c2\n",
    "napoleon  => m2\n",
    "\"\"\"\n",
    "unaries = \"\"\"\n",
    "dog  => {d1, d2, d3} \n",
    "man  => {m1, m2} \n",
    "bone => {bn1, bn2} \n",
    "\"\"\"\n",
    "binaries = \"\"\"\n",
    "bite => {(d1, bn1), (d2, bn2), (d3, bn2)} \n",
    "\"\"\"\n",
    "ternaries = \"\"\"\n",
    "give => {(c1, c2, m2), (m1, bn1, d1), (m1, bn2, d2), (m1, bn2, d3)} \n",
    "\"\"\"\n",
    "\n",
    "# world is a collection of entities and relations:\n",
    "world = entities + unaries + binaries + ternaries\n",
    "\n",
    "# parse the sentences:\n",
    "sents_reps = sem_parser(sentences, syntax, verbose=False)\n",
    "# evaluate them:\n",
    "sents_reps_vals = evaluate_sentences(sents_reps, world)\n",
    "\n",
    "# print all readings\n",
    "for i, (sent, semreps_vals) in enumerate(sents_reps_vals.items()):\n",
    "    for semrep, val in semreps_vals.items():\n",
    "        print(f\"{i+1}. {sent}:\")\n",
    "        display_translation(val, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3. Exploiting syntactic ambiguity to represent semantic ambiguity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ditransitive verbs (`DTV`) have two objects. Use the code below to inspect the lexical representation of `give(s)` in the grammar. When constructing a `VP`, we take the semantic representation of a di-trasitive verb `DTV`as a function and apply it on both direct and indirect objects: `vp = ?dtv(?obj,?pp)`. The lambda bound variables `Y` and `X` are substituted with `?obj` and `?pp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(syntax.productions()[-1])\n",
    "print(syntax.productions()[-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture we discussed that without a mechanism such as Cooper storage we would only get one scoping of quanitifers.\n",
    "\n",
    "One trick to ensure a different scoping for `give(s)` is  to create a parallel syntactic rule that contains a different internal order of composition of arguments in the `SEM`feature as follows: \n",
    "\n",
    "For example, we can change the compositional function from:\n",
    "$$\\lambda Y\\ X\\ x.X(\\lambda z.Y(\\lambda y.give(x,y,z)))$$\n",
    "to:\n",
    "$$\\lambda Y\\ X\\ x.Y(\\lambda y.X(\\lambda z.give(x,y,z)))$$\n",
    "\n",
    "As we now have two rules for `DTV` this will introduce syntactic ambiguity when a parses encouters words such `give(s)`.\n",
    "The following code adds two alternative rules to those in the previous cell. Run the code to see the parse results for sentences and their evaluation in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_string_give = r\"\"\"\n",
    "DTV[NUM=sg,SEM=<\\Y X x.Y(\\y.X(\\z.give(x,y,z)))>,TNS=pres] -> 'gives'\n",
    "DTV[NUM=pl,SEM=<\\Y X x.Y(\\y.X(\\z.give(x,y,z)))>,TNS=pres] -> 'give'\n",
    "\"\"\"\n",
    "\n",
    "# this is going to add new rules to the syntax:\n",
    "new_syntax = FeatureGrammar(\n",
    "    syntax.start(),\n",
    "    syntax.productions() + FeatureGrammar.fromstring(fcfg_string_give).productions()\n",
    ")\n",
    "\n",
    "# parse the sentences with new syntax:\n",
    "sents_reps = sem_parser(sentences, new_syntax, verbose=False)\n",
    "# evaluate them:\n",
    "sents_reps_vals = evaluate_sentences(sents_reps, world)\n",
    "\n",
    "for i, (sent, semreps_vals) in enumerate(sents_reps_vals.items()):\n",
    "    for semrep, val in semreps_vals.items():\n",
    "        print(f\"{i+1}. {sent}:\")\n",
    "        display_translation(val, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a.** Because the word `give`can now be expanded following two rules we get two extra parse trees for the second and and the third sentence. Answer the following questions: **[2 marks]**\n",
    "   - Why sentence (2) with `give` has two different readings but sentence (3) has only one reading?\n",
    "   - What is the difference between the two representations of sentence (2)?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "*Write your answers here*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1b.** When you evalute sentence (2) in the model above, one reading is True and the other is False. Change the part of the model marked with `???` so that all readings all sentences will be True. **[1 marks]** \n",
    "\n",
    "Explain why the readings are true. **[+1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ternaries = \"\"\"\n",
    "give => {(c1, c2, m2), ???}\n",
    "\"\"\"\n",
    "\n",
    "# new world\n",
    "world = entities + unaries + binaries + ternaries\n",
    "\n",
    "# evaluate them:\n",
    "sents_reps_vals = evaluate_sentences(sents_reps, world)\n",
    "\n",
    "for sent, semreps_vals in sents_reps_vals.items():\n",
    "    for semrep, val in semreps_vals.items():\n",
    "        print(f\"{sent}:\")\n",
    "        display_translation(val, semrep)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Write explanation here **\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c.** Consider a world with a `bite` relation as shown below.\n",
    "Write *another* representation of the sentence \"all dogs bite a bone\" \n",
    "that is different from the one you get above and that is *True* in this model. \n",
    "Write your answer in `???`. **[1 mark]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binaries = \"\"\"\n",
    "bite => {(d1, bn1), (d2, bn1), (d3, bn1)} \n",
    "\"\"\"\n",
    "\n",
    "# new world\n",
    "world = entities + unaries + binaries + ternaries\n",
    "\n",
    "sents_reps_copy = deepcopy(sents_reps)\n",
    "sents_reps_copy['all dogs bite a bone'].append(\n",
    "    read_expr(r\"???\")\n",
    ")\n",
    "\n",
    "# evaluate them:\n",
    "sents_reps_vals_copy = evaluate_sentences(sents_reps_copy, world)\n",
    "\n",
    "for i, (sent, semreps_vals) in enumerate(sents_reps_vals_copy.items()):\n",
    "    if sent == 'all dogs bite a bone':\n",
    "        for semrep, val in semreps_vals.items():\n",
    "            print(f\"{i+1}. {sent}:\")\n",
    "            display_translation(val, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1d.** Consider a new set of tuples representing the `give` predicate below.\n",
    "Write *another* representation for \"a man gives a bone to every dog\"\n",
    "that is *True* in the updated model.\n",
    "Write your answer in `???`. **[1 mark]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ternaries = \"\"\"\n",
    "give => {(c1, c2, m2), (m2, bn1, d1), (m1, bn1, d2), (m1, bn1, d3)}\n",
    "\"\"\"\n",
    "\n",
    "# new world\n",
    "world = entities + unaries + binaries + ternaries\n",
    "\n",
    "sents_reps_copy = deepcopy(sents_reps)\n",
    "sents_reps_copy['a man gives a bone to every dog'].append(\n",
    "    read_expr(r\"???\")\n",
    ")\n",
    "\n",
    "# evaluate them:\n",
    "sents_reps_vals_copy = evaluate_sentences(sents_reps_copy, world)\n",
    "\n",
    "for i, (sent, semreps_vals) in enumerate(sents_reps_vals_copy.items()):\n",
    "    if sent == 'a man gives a bone to every dog':\n",
    "        for semrep, val in semreps_vals.items():\n",
    "            print(f\"{i+1}. {sent}:\")\n",
    "            display_translation(val, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cooper storage [8 marks in total]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Learn about CooperSotrage\n",
    "Study the following grammar with a `SEM` that is split between `CORE` and `STORE`. However, in this example, we never add anything to the `STORE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fcfg_storage_base = r\"\"\"\n",
    "% start S\n",
    "\n",
    "S[SEM=[CORE=<?subj(?vp)>, STORE=(?b1+?b2)]] -> NP[NUM=?n,SEM=[CORE=?subj, STORE=?b1]] VP[NUM=?n,SEM=[CORE=?vp, STORE=?b2]]\n",
    "\n",
    "Nom[NUM=?n,SEM=?s] -> N[NUM=?n,SEM=?s]\n",
    "\n",
    "VP[NUM=?n,SEM=?s] -> IV[NUM=?n,SEM=?s]\n",
    "VP[NUM=?n,SEM=[CORE=<?v(?obj)>, STORE=(?b1+?b2)]] -> TV[NUM=?n,SEM=[CORE=?v, STORE=?b1]] NP[SEM=[CORE=?obj, STORE=?b2]]\n",
    "VP[NUM=?n,SEM=[CORE=<?v(?pp)(?obj)>, STORE=(?b1+?b2+?b3)]] -> DTV[NUM=?n,SEM=[CORE=?v, STORE=?b1]] NP[SEM=[CORE=?obj, STORE=?b2]] PP[+TO,SEM=[CORE=?pp, STORE=?b3]]\n",
    "\n",
    "PP[+TO, SEM=[CORE=?np, STORE=?b1]] -> P[+TO] NP[SEM=[CORE=?np, STORE=?b1]]\n",
    "\"\"\"\n",
    "\n",
    "fcfg_storage_lexicon = r\"\"\"\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(angus)>, STORE=(/)]] -> 'Angus'\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(cyril)>, STORE=(/)]] -> 'Cyril'\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(irene)>, STORE=(/)]] -> 'Irene'\n",
    "\n",
    "Det[NUM=sg,SEM=[CORE=<\\P Q.all x.(P(x) -> Q(x))>, STORE=(/)]] -> 'every'\n",
    "Det[NUM=sg,SEM=[CORE=<\\P Q.exists x.(P(x) & Q(x))>, STORE=(/)]] -> 'a'\n",
    "\n",
    "N[NUM=sg,SEM=[CORE=<\\x.library(x)>, STORE=(/)]] -> 'library'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.girl(x)>, STORE=(/)]] -> 'girl'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.boy(x)>, STORE=(/)]] -> 'boy'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.book(x)>, STORE=(/)]] -> 'book'\n",
    "\n",
    "IV[NUM=sg,SEM=[CORE=<\\x.smile(x)>, STORE=(/)],TNS=pres] -> 'smiles' \n",
    "\n",
    "TV[NUM=sg,SEM=[CORE=<\\X x.X(\\y.read(x,y))>, STORE=(/)],TNS=pres] -> 'reads'\n",
    "\n",
    "DTV[NUM=sg,SEM=[CORE=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>, STORE=(/)],TNS=pres] -> 'gives'\n",
    "\n",
    "P[+to] -> 'to'\n",
    "\"\"\" \n",
    "\n",
    "fcfg_storage_np = r\"\"\"\n",
    "NP[NUM=?n,SEM=[CORE=?np, STORE=?b1]] -> PropN[NUM=?n,SEM=[CORE=?np, STORE=?b1]]\n",
    "NP[NUM=?n,SEM=[CORE=<?det(?nom)>, STORE=(?b1+?b2)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] Nom[NUM=?n,SEM=[CORE=?nom, STORE=?b2]]\n",
    "\"\"\"\n",
    "\n",
    "sentences = [\n",
    "    'Angus reads a book',\n",
    "    'every girl reads a book',\n",
    "    'every library gives a book to a girl',\n",
    "]\n",
    "\n",
    "fcfg_storage = fcfg_storage_base + fcfg_storage_np + fcfg_storage_lexicon\n",
    "cs_syntax = FeatureGrammar.fromstring(fcfg_storage)\n",
    "sents_reps = sem_parser(sentences, cs_syntax, verbose=False, is_cs=True)\n",
    "\n",
    "for i, (sent, semreps) in enumerate(sents_reps.items()):\n",
    "    counter = 0\n",
    "    print(f\"{i+1}. {sent}\")\n",
    "    for semrep in semreps:\n",
    "        counter += 1\n",
    "        display_translation(counter, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following change to the `NP` rule we push representations to the `STORE` and replace them with a simple varible in the `CORE` (which is then type raised to <<e,t>,t> so that it it can combine with a transitive verb entry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_storage_np = r\"\"\"\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?np, @x)>+?b1)]] -> PropN[NUM=?n,SEM=[CORE=?np, STORE=?b1]]\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?det(?nom), @x)>+?b1+?b2)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] Nom[NUM=?n,SEM=[CORE=?nom, STORE=?b2]]\n",
    "\"\"\"\n",
    "\n",
    "sentences = [\n",
    "    'Angus reads a book',\n",
    "    'every girl reads a book',\n",
    "    'every library gives a book to a girl',\n",
    "]\n",
    "\n",
    "fcfg_storage = fcfg_storage_base + fcfg_storage_np + fcfg_storage_lexicon\n",
    "cs_syntax = FeatureGrammar.fromstring(fcfg_storage)\n",
    "sents_reps = sem_parser(sentences, cs_syntax, verbose=False, is_cs=True)\n",
    "\n",
    "for i, (sent, semreps) in enumerate(sents_reps.items()):\n",
    "    counter = 0\n",
    "    print(f\"{i+1}. {sent}\")\n",
    "    for semrep in semreps:\n",
    "        counter += 1\n",
    "        display_translation(counter, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a.** There are two identical readings of the first sentence. Why is this so? Suggest a change that would ensure you do not get doublicate readings for the first sentence but you get  alternative readings for the other sentence. **[2 marks]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "* Write explanation here *\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Angus reads a book',\n",
    "    'every girl reads a book'\n",
    "]\n",
    "\n",
    "fcfg_storage_np = r\"\"\"\n",
    "## Change the rule below:\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?np, @x)>+?b1)]] -> PropN[NUM=?n,SEM=[CORE=?np, STORE=?b1]]\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?det(?nom), @x)>+?b1+?b2)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] Nom[NUM=?n,SEM=[CORE=?nom, STORE=?b2]]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "fcfg_storage = fcfg_storage_base + fcfg_storage_np + fcfg_storage_lexicon \n",
    "cs_syntax = FeatureGrammar.fromstring(fcfg_storage)\n",
    "sents_reps = sem_parser(sentences, cs_syntax, verbose=False, is_cs=True)\n",
    "\n",
    "for i, (sent, semreps) in enumerate(sents_reps.items()):\n",
    "    counter = 0\n",
    "    print(f\"{i+1}. {sent}\")\n",
    "    for semrep in semreps:\n",
    "        counter += 1\n",
    "        display_translation(counter, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2b.** Extend the grammar below to cover the following sentences: **[6 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'every library gives a book to every girl and every boy',\n",
    "    'no library gives every book to a boy',\n",
    "    'a boy and a girl read all books',\n",
    "    'Angus and Irene read all books',\n",
    "]\n",
    "\n",
    "# your answers\n",
    "fcfg_storage_answers_1 = r\"\"\"\n",
    "### Replace X with their proper representations\n",
    "X -> 'no'\n",
    "X -> 'all'\n",
    "X -> 'books'\n",
    "X -> 'read'\n",
    "\"\"\"\n",
    "\n",
    "fcfg_storage_answers_2 = r\"\"\"\n",
    "### Correct the conjunction rule here. Replace xxx and ??? with the correct answer:\n",
    "NP[NUM=xxx, SEM=[CORE=<???>, STORE=(?b1+?b2)]] -> NP[NUM=?num1, SEM=[CORE=?n1, STORE=?b1]] CONJ NP[NUM=?num2, SEM=[CORE=?n2, STORE=?b2]]\n",
    "CONJ -> 'and'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "fcfg_storage = fcfg_storage_base + fcfg_storage_np + fcfg_storage_lexicon + fcfg_storage_answers_1 + fcfg_storage_answers_2\n",
    "cs_syntax = FeatureGrammar.fromstring(fcfg_storage)\n",
    "sents_reps = sem_parser(sentences, cs_syntax, verbose=False, is_cs=True)\n",
    "\n",
    "for i, (sent, semreps) in enumerate(sents_reps.items()):\n",
    "    counter = 0\n",
    "    print(f\"{i+1}. {sent}\")\n",
    "    for semrep in semreps:\n",
    "        counter += 1\n",
    "        display_translation(counter, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** Add the quantified expressions to the `STORE` only in the conjunction rule. Compare the number of readings you get now for the sentence below. Are there any invalid readings? If so, why? **[3 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'every library gives a book to every girl and every boy',\n",
    "]\n",
    "\n",
    "fcfg_storage_answers_2 = r\"\"\"\n",
    "### Correct the conjunction rule here. Replace xxx and ??? with the correct answer:\n",
    "NP[NUM=xxx, SEM=[CORE=<\\P.P(@x)>, STORE=((<bo(???, @x)>)+?b1+?b2)]] -> NP[NUM=?num1, SEM=[CORE=?n1, STORE=?b1]] CONJ NP[NUM=?num2, SEM=[CORE=?n2, STORE=?b2]]\n",
    "CONJ -> 'and'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "fcfg_storage = fcfg_storage_base + fcfg_storage_np + fcfg_storage_lexicon + fcfg_storage_answers_1 + fcfg_storage_answers_2\n",
    "cs_syntax = FeatureGrammar.fromstring(fcfg_storage)\n",
    "sents_reps = sem_parser(sentences, cs_syntax, verbose=False, is_cs=True)\n",
    "\n",
    "for i, (sent, semreps) in enumerate(sents_reps.items()):\n",
    "    counter = 0\n",
    "    print(f\"{i+1}. {sent}\")\n",
    "    for semrep in semreps:\n",
    "        counter += 1\n",
    "        display_translation(counter, semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This part of the assignment has a total of 14 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
