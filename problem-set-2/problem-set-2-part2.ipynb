{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 - Part 2: Inference\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the following instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "In this part you will work on a problem from the FraCaS test suite. The goal of this problem set is to extend the grammar for Cooper storage from the previous part, apply the sentences to a theorem prover and a model builder, analyse their results and conclude about the inference. Since every sentence may be translated to several formulae there will also be several inference steps and thus several results.\n",
    "\n",
    "\n",
    "\n",
    "### Pre-requisite knowledge\n",
    "\n",
    "From `problem-set-1`:\n",
    "- First order logic\n",
    "- Lambda calculus\n",
    "- Feature unification context free grammar\n",
    "\n",
    "From `problem-set-2-part1.ipynb`:\n",
    "- Cooper storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task requires NLTK and Jupyter Notebook (IPython package).\n",
    "import nltk\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.sem import cooper_storage as cs\n",
    "\n",
    "from utils import display_latex, display_translation, display_tree, display, Markdown\n",
    "from utils2 import sem_parser, evaluate_sentences, syntax, syntax_notv\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Extending the grammar [6 marks]\n",
    "\n",
    "Extend the grammar below so that it covers the sentences of the inference problem based on FraCaS problem 057.\n",
    "\n",
    "Several solutions are possible, also some that would not result in entailment. Our lexical knowledge about words leads us how to formalise them in first order logic. Therefore, make sure that you handle the PP attachment in a away that you will be able to show entailments between examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'a Portuguese delegate published the result on climate',\n",
    "    'a Portuguese delegate published a result',\n",
    "    'a Portuguese delegate published the result',\n",
    "    'a Portuguese published a result',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_storage_base = r\"\"\"\n",
    "% start S\n",
    "\n",
    "S[SEM=[CORE=<?subj(?vp)>, STORE=(?b1+?b2)]] -> NP[NUM=?n,SEM=[CORE=?subj, STORE=?b1]] VP[NUM=?n,SEM=[CORE=?vp, STORE=?b2]]\n",
    "\n",
    "Nom[NUM=?n,SEM=?s] -> N[NUM=?n,SEM=?s]\n",
    "\n",
    "VP[NUM=?n,SEM=?s] -> IV[NUM=?n,SEM=?s]\n",
    "VP[NUM=?n,SEM=[CORE=<?v(?obj)>, STORE=(?b1+?b2)]] -> TV[NUM=?n,SEM=[CORE=?v, STORE=?b1]] NP[SEM=[CORE=?obj, STORE=?b2]]\n",
    "VP[NUM=?n,SEM=[CORE=<?v(?pp)(?obj)>, STORE=(?b1+?b2+?b3)]] -> DTV[NUM=?n,SEM=[CORE=?v, STORE=?b1]] NP[SEM=[CORE=?obj, STORE=?b2]] PP[+TO,SEM=[CORE=?pp, STORE=?b3]]\n",
    "\n",
    "PP[+TO, SEM=[CORE=?np, STORE=?b1]] -> P[+TO] NP[SEM=[CORE=?np, STORE=?b1]]\n",
    "\"\"\"\n",
    "\n",
    "fcfg_storage_lexicon = r\"\"\"\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(angus)>, STORE=(/)]] -> 'Angus'\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(cyril)>, STORE=(/)]] -> 'Cyril'\n",
    "PropN[NUM=sg,SEM=[CORE=<\\P.P(irene)>, STORE=(/)]] -> 'Irene'\n",
    "\n",
    "Det[NUM=sg,SEM=[CORE=<\\P Q.all x.(P(x) -> Q(x))>, STORE=(/)]] -> 'every'\n",
    "Det[NUM=sg,SEM=[CORE=<\\P Q.exists x.(P(x) & Q(x))>, STORE=(/)]] -> 'a'\n",
    "\n",
    "N[NUM=sg,SEM=[CORE=<\\x.library(x)>, STORE=(/)]] -> 'library'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.girl(x)>, STORE=(/)]] -> 'girl'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.boy(x)>, STORE=(/)]] -> 'boy'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.book(x)>, STORE=(/)]] -> 'book'\n",
    "\n",
    "IV[NUM=sg,SEM=[CORE=<\\x.smile(x)>, STORE=(/)],TNS=pres] -> 'smiles' \n",
    "\n",
    "TV[NUM=sg,SEM=[CORE=<\\X x.X(\\y.read(x,y))>, STORE=(/)],TNS=pres] -> 'reads'\n",
    "\n",
    "DTV[NUM=sg,SEM=[CORE=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>, STORE=(/)],TNS=pres] -> 'gives'\n",
    "\n",
    "P[+to] -> 'to'\n",
    "\"\"\" \n",
    "\n",
    "fcfg_storage_np = r\"\"\"\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?np, @x)>+?b1)]] -> PropN[NUM=?n,SEM=[CORE=?np, STORE=?b1]]\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?det(?nom), @x)>+?b1+?b2)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] Nom[NUM=?n,SEM=[CORE=?nom, STORE=?b2]]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code resolves the readings from the Cooper storage. We collect the readings in a dictionary where the key is a sentence string and the value is a list of readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to parse line 51: P[+LOC,SEM=[CORE=<\\P y exists x.(on(x,y) & P(x))>, STORE=(/)]] -> 'on' #Mehdis\nError parsing feature structure\n    P[+LOC,SEM=[CORE=<\\P y exists x.(on(x,y) & P(x))>, STORE=(/)]] -> 'on' #Mehdis\n                                                                           ^ Expected open bracket or identifier",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(self, s, position, reentrances, fstruct)\u001b[0m\n\u001b[1;32m   2253\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2254\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreentrances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstruct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2255\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36m_read_partial\u001b[0;34m(self, s, position, reentrances, fstruct)\u001b[0m\n\u001b[1;32m   2272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'open bracket or identifier'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: ('open bracket or identifier', 71)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1455\u001b[0m                 \u001b[0;31m# expand out the disjunctions on the RHS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m                 \u001b[0mproductions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_read_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1457\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36m_read_production\u001b[0;34m(line, nonterm_parser, probabilistic)\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m             \u001b[0mnonterm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0mrhsides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonterm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36mread_partial\u001b[0;34m(self, s, position, reentrances, fstruct)\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2258\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/featstruct.py\u001b[0m in \u001b[0;36m_error\u001b[0;34m(self, s, expected, position)\u001b[0m\n\u001b[1;32m   2471\u001b[0m         )\n\u001b[0;32m-> 2472\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error parsing feature structure\n    P[+LOC,SEM=[CORE=<\\P y exists x.(on(x,y) & P(x))>, STORE=(/)]] -> 'on' #Mehdis\n                                                                           ^ Expected open bracket or identifier",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-56d8ab340efb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# this is going to add new rules to the syntax:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mfcfg_storage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcfg_storage_base\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfcfg_storage_np\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfcfg_storage_lexicon\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfcfg_storage_answers_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mnew_syntax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureGrammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcfg_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(cls, input, features, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         start, productions = read_grammar(\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfstruct_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m         )\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproductions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mread_grammar\u001b[0;34m(input, nonterm_parser, probabilistic, encoding)\u001b[0m\n\u001b[1;32m   1456\u001b[0m                 \u001b[0mproductions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_read_production\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonterm_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobabilistic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unable to parse line %s: %s\\n%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlinenum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mproductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to parse line 51: P[+LOC,SEM=[CORE=<\\P y exists x.(on(x,y) & P(x))>, STORE=(/)]] -> 'on' #Mehdis\nError parsing feature structure\n    P[+LOC,SEM=[CORE=<\\P y exists x.(on(x,y) & P(x))>, STORE=(/)]] -> 'on' #Mehdis\n                                                                           ^ Expected open bracket or identifier"
     ]
    }
   ],
   "source": [
    "# your answers\n",
    "fcfg_storage_answers_1 = r\"\"\"\n",
    "### Replace X with their proper representations\n",
    "ADJ[NUM=sg,SEM=[CORE=<\\P x.(P(x) & portuguese(x))>, STORE=(/)]] -> 'Portuguese'\n",
    "\n",
    "N[NUM=sg,SEM=[CORE=<\\x.portuguese(x)>, STORE=(/)]] -> 'Portuguese'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.delegate(x)>, STORE=(/)]] -> 'delegate'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.result(x)>, STORE=(/)]] -> 'result'\n",
    "N[NUM=sg,SEM=[CORE=<\\x.climate(x)>, STORE=(/)]] -> 'climate'\n",
    "\n",
    "TV[NUM=sg,SEM=[CORE=<\\X x.X(\\y.publish(x,y))>, STORE=(/)],TNS=past] -> 'published'\n",
    "\n",
    "Det[SEM=[CORE=<\\P Q.exists x.(P(x) & all y.(P(y) -> x=y) & Q(x))>, STORE=(/)]] -> 'the'\n",
    "\n",
    "P[+on] -> 'on' \n",
    "#P[+LOC,SEM=[CORE=<\\X x.X(\\y.on(x,y))>, STORE=(/)]] -> 'on' \n",
    "P[+LOC,SEM=[CORE=<\\P y exists x.(on(x,y) & P(x))>, STORE=(/)]] -> 'on' #Mehdis\n",
    "PP[+ON, SEM=[CORE=?n, STORE=?b1]] -> P[+ON] N[SEM=[CORE=?n, STORE=?b1]]\n",
    "#PP[+ON, SEM=[CORE=<?p(?nom)>, STORE=?b1+?b2]] -> P[SEM=[CORE=?p, STORE=?b1]] Nom[SEM=[CORE=?nom, STORE=?b2]] #Mehdis förslag\n",
    "\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?np, @x)>+?b1)]] -> N[NUM=?n,SEM=[CORE=?n, STORE=?b1]]\n",
    "VP[NUM=?n,SEM=[CORE=<?v(?obj)(?pp)>, STORE=(?b1+?b2+?b3)]] -> TV[NUM=?n,SEM=[CORE=?v, STORE=?b1]] NP[SEM=[CORE=?obj, STORE=?b2]] PP[+ON,SEM=[CORE=?pp, STORE=?b3]]\n",
    "NP[NUM=?n,SEM=[CORE=<\\P.P(@x)>, STORE=(<bo(?det(?adj(?nom)), @x)>+?b1+?b2+?b3)]] -> Det[NUM=?n,SEM=[CORE=?det, STORE=?b1]] ADJ[NUM=?n,SEM=[CORE=?adj, STORE=?b2]] Nom[NUM=?n,SEM=[CORE=?nom, STORE=?b3]]\n",
    "## Extend the other missig rules too\n",
    "\"\"\"\n",
    "\n",
    "# this is going to add new rules to the syntax:\n",
    "fcfg_storage = fcfg_storage_base + fcfg_storage_np + fcfg_storage_lexicon + fcfg_storage_answers_1\n",
    "new_syntax = FeatureGrammar.fromstring(fcfg_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. a Portuguese delegate published the result on climate\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"1\": $\\exists\\ x.(result(x)\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (x\\ =\\ y))\\ \\land\\ \\exists\\ z_{336}.(delegate(z_{336})\\ \\land\\ portuguese(z_{336})\\ \\land\\ publish(\\lambda\\ z_{335}.climate(z_{335}),x,z_{336})))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"2\": $\\exists\\ x.(delegate(x)\\ \\land\\ portuguese(x)\\ \\land\\ \\exists\\ z_{338}.(result(z_{338})\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (z_{338}\\ =\\ y))\\ \\land\\ publish(\\lambda\\ z_{337}.climate(z_{337}),z_{338},x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"3\": $\\exists\\ x.(result(x)\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (x\\ =\\ y))\\ \\land\\ \\exists\\ z_{340}.(delegate(z_{340})\\ \\land\\ portuguese(z_{340})\\ \\land\\ publish(\\lambda\\ z_{339}.climate(z_{339}),x,z_{340})))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"4\": $\\exists\\ x.(delegate(x)\\ \\land\\ portuguese(x)\\ \\land\\ \\exists\\ z_{342}.(result(z_{342})\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (z_{342}\\ =\\ y))\\ \\land\\ publish(\\lambda\\ z_{341}.climate(z_{341}),z_{342},x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. a Portuguese delegate published a result\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"1\": $\\exists\\ x.(result(x)\\ \\land\\ \\exists\\ z_{343}.(delegate(z_{343})\\ \\land\\ portuguese(z_{343})\\ \\land\\ publish(z_{343},x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"2\": $\\exists\\ x.(delegate(x)\\ \\land\\ portuguese(x)\\ \\land\\ \\exists\\ z_{344}.(result(z_{344})\\ \\land\\ publish(x,z_{344})))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. a Portuguese delegate published the result\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"1\": $\\exists\\ x.(result(x)\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (x\\ =\\ y))\\ \\land\\ \\exists\\ z_{345}.(delegate(z_{345})\\ \\land\\ portuguese(z_{345})\\ \\land\\ publish(z_{345},x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"2\": $\\exists\\ x.(delegate(x)\\ \\land\\ portuguese(x)\\ \\land\\ \\exists\\ z_{346}.(result(z_{346})\\ \\land\\ \\forall\\ y.(result(y)\\ \\to\\ (z_{346}\\ =\\ y))\\ \\land\\ publish(x,z_{346})))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. a Portuguese published a result\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"1\": $\\exists\\ x.(result(x)\\ \\land\\ \\exists\\ z_{347}.(portuguese(z_{347})\\ \\land\\ publish(z_{347},x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"2\": $\\exists\\ x.(portuguese(x)\\ \\land\\ \\exists\\ z_{348}.(result(z_{348})\\ \\land\\ publish(x,z_{348})))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_readings = sem_parser(sentences, new_syntax, verbose=False, is_cs=True)\n",
    "\n",
    "# print all readings\n",
    "for i, (sent, semreps) in enumerate(sentence_readings.items()):\n",
    "    counter = 0\n",
    "    print(f\"{i+1}. {sent}\")\n",
    "    for semrep in semreps:\n",
    "        counter += 1\n",
    "        display_translation(counter, semrep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a Portuguese delegate published the result on climate': [],\n",
       " 'a Portuguese delegate published a result': [<ExistsExpression exists x.(result(x) & exists z132.(delegate(z132) & portuguese(z132) & publish(z132,x)))>,\n",
       "  <ExistsExpression exists x.(delegate(x) & portuguese(x) & exists z133.(result(z133) & publish(x,z133)))>],\n",
       " 'a Portuguese delegate published the result': [<AndExpression (exists x.(result(x) & (all y.result(y) -> (x = y2))) & exists x.(delegate(x) & portuguese(x) & publish(x,x2)))>,\n",
       "  <ExistsExpression exists x.(delegate(x) & portuguese(x) & exists z134.(result(z134) & (all y.result(y) -> (z134 = y2))) & publish(x,x2))>],\n",
       " 'a Portuguese published a result': [<ExistsExpression exists x.(result(x) & exists z135.(portuguese(z135) & publish(z135,x)))>,\n",
       "  <ExistsExpression exists x.(portuguese(x) & exists z136.(result(z136) & publish(x,z136)))>]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure understanding this data structure:\n",
    "sentence_readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Using Prover9 [4 marks in total]\n",
    "\n",
    "Show which readings of (1) entail a reading of (2). **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-3202ee08fd64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m'----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mapply_theorem_prover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-146-3202ee08fd64>\u001b[0m in \u001b[0;36mapply_theorem_prover\u001b[0;34m(premises, goals)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_theorem_prover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpremises\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgoals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpremise\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpremises\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgoal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgoals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Premise      : %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpremise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not iterable"
     ]
    }
   ],
   "source": [
    "# There is something missing in this code. You will have to fix it, before you can run it.\n",
    "\n",
    "prover = nltk.Prover9()\n",
    "\n",
    "def apply_theorem_prover(premises, goals):\n",
    "    for premise in premises:\n",
    "        for goal in goals:\n",
    "            print(\"Premise      : %s\" % (premise))\n",
    "            print(\"Goal         : %s\" % (goal))\n",
    "            print(\"Prover result: %s\" % (...))\n",
    "            print(10*'----')\n",
    "            \n",
    "apply_theorem_prover(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the readings of (1) entail all the readings of (2)? If not, why not? **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which readings of (1) entail a reading of (4). **[1 mark]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is something missing in this code. You will have to fix it, before you can run it.\n",
    "\n",
    "apply_theorem_prover(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the readings of (1) entail all the readings of (4)? If not, why not? **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Using Mace [2 marks in total]\n",
    "\n",
    "Show whether (1) entails (3). **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is something missing in this code. \n",
    "\n",
    "def apply_model_builder(premises,goals):\n",
    "    for premise in premises:\n",
    "        for goal in goals:\n",
    "            print(\"Premise : %s\" % (premise))\n",
    "            print(\"Goal    : %s\" % (goal))\n",
    "            mc = nltk.MaceCommand(..., assumptions=...)\n",
    "            ...\n",
    "            print(\"a model:\")\n",
    "            print(mc.valuation)\n",
    "            print(10*'...')\n",
    "\n",
    "apply_model_builder(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why. **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This part of the assignment has a total of 12 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
