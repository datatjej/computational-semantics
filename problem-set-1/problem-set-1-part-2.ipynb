{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 1 - Part 2: Lambda Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the following instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task needs NLTK and Jupyter Notebook (IPython package).\n",
    "import nltk\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from utils import display_latex, display_translation, display_tree, display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Types of (Expression) objects in Python/NLTK and semantic types\n",
    "\n",
    "First order logic expressions and lambda expressions are our **object language** that we use to represent semantics of linguistic expressions. The object language is implemented in Python which is the **meta language**. We write logic and lambda expressions as strings that are then converted to Python/NLTK objects that are then processed with Python methods.\n",
    "\n",
    "The goal of this question is to learn about **types**. In the object language we use types that correspond to the meaning of the corresponding expressions in natural language (the basic types `e` and `t` and function types based on these such as `<e,t>`), in the meta language we use types that are practically required for computation (`<IndividualVariableExpression x>`). How do these type systems compare?\n",
    "\n",
    "We can translate logic expressions written as a string into one of the `nltk.sem.logic.Expression` types as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$x$ = `<IndividualVariableExpression x>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P$ = `<FunctionVariableExpression P>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$rob$ = `<ConstantExpression rob>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\lambda\\ x.P(x)$ = `<LambdaExpression \\x.P(x)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\lambda\\ x.homosapien(x)$ = `<LambdaExpression \\x.homosapien(x)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(x)$ = `<ApplicationExpression P(x)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$P(rob)$ = `<ApplicationExpression P(rob)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$homosapien(rob)$ = `<ApplicationExpression homosapien(rob)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$(\\lambda\\ y\\ x.love(x,y))(rob)$ = `<ApplicationExpression (\\y x.love(x,y))(rob)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$(homosapien(rob)\\ \\land\\ run(rob))$ = `<AndExpression (homosapien(rob) & run(rob))>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\exists\\ x.(homosapien(x)\\ \\land\\ run(x))$ = `<ExistsExpression exists x.(homosapien(x) & run(x))>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\forall\\ x.(homosapien(x)\\ \\land\\ run(x))$ = `<AllExpression all x.(homosapien(x) & run(x))>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "----\n",
       "\n",
       "**Note**: *Python interprets `\\` as a marker for special characters.\n",
       "To prevent this, we use `r` in `r\"strings\"` in order to force the raw interpretation of strings.*\n",
       "\n",
       "----"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_expr = nltk.sem.Expression.fromstring\n",
    "\n",
    "# different representations have different valid types:\n",
    "expressions = [\n",
    "    read_expr(r\"x\"),\n",
    "    read_expr(r\"P\"),\n",
    "    read_expr(r\"rob\"),\n",
    "    read_expr(r\"\\x.P(x)\"),\n",
    "    read_expr(r\"\\x.homosapien(x)\"),\n",
    "    read_expr(r\"P(x)\"),\n",
    "    read_expr(r\"P(rob)\"),\n",
    "    read_expr(r\"homosapien(rob)\"),\n",
    "    read_expr(r\"(\\y \\x.love(x, y))(rob)\"),\n",
    "    read_expr(r\"homosapien(rob) & run(rob)\"),\n",
    "    read_expr(r\"exists x.(homosapien(x) & run(x))\"),\n",
    "    read_expr(r\"all x.(homosapien(x) & run(x))\"),\n",
    "]\n",
    "\n",
    "for expr in expressions:\n",
    "    display_latex(expr, with_types=True)\n",
    "\n",
    "display(Markdown(r\"\"\"----\n",
    "\n",
    "**Note**: *Python interprets `\\` as a marker for special characters.\n",
    "To prevent this, we use `r` in `r\"strings\"` in order to force the raw interpretation of strings.*\n",
    "\n",
    "----\"\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the following type assumptions:\n",
    "```\n",
    "x : e\n",
    "P : <e, t>\n",
    "rob: e\n",
    "```\n",
    "**1a.** What is the semantic type of each expression below? Assume an approprate type for `homosapien` and `run` based on how they are used in other examples. **[5 marks]**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `???` below:\n",
    "\n",
    "```\n",
    "P(x): ???\n",
    "P(rob): ???\n",
    "homosapien(rob): ???\n",
    "homosapien: ???\n",
    "\\x.P(x): ???\n",
    "\\x.homosapien(x): ???\n",
    "(\\y \\x.love(x, y))(rob): ???\n",
    "homosapien(rob) & run(rob): ???\n",
    "exists x.(homosapien(x) & run(x)): ???\n",
    "all x.(homosapien(x) & run(x)): ???\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1b. Some well-formed NLTK expressions do not have a valid semantic type. Explain the issue in the expression below **[2 marks]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$(rob\\ \\land\\ marry)$ = `<AndExpression (rob & marry)>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_latex(read_expr(r\"rob & marry\"), with_types=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Translate verb phrases\n",
    "\n",
    "Translate the verb phrases using $\\lambda$ abstracts and verify the resulting formulae with `Expression.fromstring`. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"read by Rob\": $\\lambda\\ x.read(rob,x)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"read a book\": $\\lambda\\ x.\\exists\\ y.(book(y)\\ \\land\\ read(x,y))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "translations = {\n",
    "    \"read by Rob\": read_expr(r\"\\x.read(rob, x)\"),\n",
    "    \"read a book\": read_expr(r\"\\x. exists y. (book(y) & read(x, y))\"),\n",
    "}\n",
    "\n",
    "for text, expr in translations.items():\n",
    "    display_translation(text, expr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace `xxx` with valid representations in the dictionary of expressions **[4 marks]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\"be admired by no-one\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"catch a fish and eat it\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"read a book or watch a film\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\"give every boy a dime\": `<ConstantExpression xxx>`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fix the following translations:\n",
    "translations = {\n",
    "    \"be admired by no-one\":        read_expr(r\"xxx\"),\n",
    "    \"catch a fish and eat it\":     read_expr(r\"xxx\"),\n",
    "    \"read a book or watch a film\": read_expr(r\"xxx\"),\n",
    "    \"give every boy a dime\":       read_expr(r\"xxx\")\n",
    "}\n",
    "\n",
    "for text, expr in translations.items():\n",
    "    display_translation(text, expr, to_latex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Function application and $\\beta$-reduction\n",
    "In the following examples some code has been deleted and replaced with `<????>`. What has been deleted? Verify that your answer is correct. **[4 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "$????(pip)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$like(pip,rob)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$????(\\lambda\\ x.play(x,scherzo))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$play(pip,scherzo)$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$????(\\lambda\\ x.play(x,etude))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\exists\\ x.(woman(x)\\ \\land\\ play(x,etude))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$????(\\lambda\\ P.\\forall\\ x.(musician(x)\\ \\to\\ P(x)))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "$\\lambda\\ x.\\forall\\ z_{2}.(musician(z_{2})\\ \\to\\ like(x,z_{2}))$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'pip')\n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with reuslt like(pip,rob).\n",
    "display_latex(read_expr(r\"like(pip,rob)\"))\n",
    "\n",
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'\\x.play(x,scherzo)') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2)\n",
    "display_latex(e3.simplify())\n",
    "# with result play(pip,scherzo).\n",
    "display_latex(read_expr(r\"play(pip,scherzo)\"))\n",
    "\n",
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'\\x.play(x,etude)') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with result exists x.(woman(x) & play(x,etude)).\n",
    "display_latex(read_expr(r\"exists x.(woman(x) & play(x,etude))\"))\n",
    "\n",
    "e1 = read_expr(r'????')\n",
    "e2 = read_expr(r'\\P.all x. (musician(x) -> P(x))') \n",
    "e3 = nltk.sem.ApplicationExpression(e1,e2) \n",
    "display_latex(e3.simplify())\n",
    "# with result \\x.all z2.(musician(z2) -> like(x,z2)).\n",
    "display_latex(read_expr(r\"\\x.all z2.(musician(z2) -> like(x,z2))\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extending the FCFG grammar\n",
    "\n",
    "Extend the grammar simple_sem.fcfg that comes with NLTK `(~/nltk_data/grammars/book_grammars/)` so that it will cover the following sentences:\n",
    "\n",
    "- no man gives a bone to a dog **[4 marks]**\n",
    "- a boy and a girl chased every dog **[2 marks]**\n",
    "- every dog chased a boy and a girl **[2 marks]**\n",
    "- a brown cat chases a white dog **[4 marks]**\n",
    "\n",
    "The last example includes adjectives. Several different kinds of adjectives are discussed in the literature [(cf. Kennedy, 2012)](http://semantics.uchicago.edu/kennedy/docs/routledge.pdf). In this example we have an intersective adjective. The denotiation we want for \"brown cat\" is a a set that we get by intersecting the set of individuals that are brown and the set of individuals that are cats.\n",
    "\n",
    "C. Kennedy. Adjectives. In G. Russell, editor, The Routledge Companion to Philosophy of Language, chapter 3.3, pages 328–341. Routledge, 2012.\n",
    "\n",
    "The original grammar is included in the code below as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_string_orginal = r\"\"\"\n",
    "% start S\n",
    "############################\n",
    "# Grammar Rules\n",
    "#############################\n",
    "\n",
    "S[SEM = <?subj(?vp)>] -> NP[NUM=?n,SEM=?subj] VP[NUM=?n,SEM=?vp]\n",
    "\n",
    "NP[NUM=?n,SEM=<?det(?nom)> ] -> Det[NUM=?n,SEM=?det]  Nom[NUM=?n,SEM=?nom]\n",
    "NP[LOC=?l,NUM=?n,SEM=?np] -> PropN[LOC=?l,NUM=?n,SEM=?np]\n",
    "\n",
    "Nom[NUM=?n,SEM=?nom] -> N[NUM=?n,SEM=?nom]\n",
    "\n",
    "VP[NUM=?n,SEM=?v] -> IV[NUM=?n,SEM=?v]\n",
    "VP[NUM=?n,SEM=<?v(?obj)>] -> TV[NUM=?n,SEM=?v] NP[SEM=?obj]\n",
    "VP[NUM=?n,SEM=<?v(?obj,?pp)>] -> DTV[NUM=?n,SEM=?v] NP[SEM=?obj] PP[+TO,SEM=?pp]\n",
    "\n",
    "PP[+TO, SEM=?np] -> P[+TO] NP[SEM=?np]\n",
    "\n",
    "#############################\n",
    "# Lexical Rules\n",
    "#############################\n",
    "\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(angus)>] -> 'Angus'\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(cyril)>] -> 'Cyril'\n",
    "PropN[-LOC,NUM=sg,SEM=<\\P.P(irene)>] -> 'Irene'\n",
    " \n",
    "Det[NUM=sg,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'every'\n",
    "Det[NUM=pl,SEM=<\\P Q.all x.(P(x) -> Q(x))>] -> 'all'\n",
    "Det[SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'some'\n",
    "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'a'\n",
    "Det[NUM=sg,SEM=<\\P Q.exists x.(P(x) & Q(x))>] -> 'an'\n",
    "\n",
    "N[NUM=sg,SEM=<\\x.man(x)>] -> 'man'\n",
    "N[NUM=sg,SEM=<\\x.girl(x)>] -> 'girl'\n",
    "N[NUM=sg,SEM=<\\x.boy(x)>] -> 'boy'\n",
    "N[NUM=sg,SEM=<\\x.bone(x)>] -> 'bone'\n",
    "N[NUM=sg,SEM=<\\x.ankle(x)>] -> 'ankle'\n",
    "N[NUM=sg,SEM=<\\x.dog(x)>] -> 'dog'\n",
    "N[NUM=pl,SEM=<\\x.dog(x)>] -> 'dogs'\n",
    "\n",
    "IV[NUM=sg,SEM=<\\x.bark(x)>,TNS=pres] -> 'barks'\n",
    "IV[NUM=pl,SEM=<\\x.bark(x)>,TNS=pres] -> 'bark'\n",
    "IV[NUM=sg,SEM=<\\x.walk(x)>,TNS=pres] -> 'walks'\n",
    "IV[NUM=pl,SEM=<\\x.walk(x)>,TNS=pres] -> 'walk'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=pres] -> 'chases'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.chase(x,y))>,TNS=pres] -> 'chase'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.see(x,y))>,TNS=pres] -> 'sees'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.see(x,y))>,TNS=pres] -> 'see'\n",
    "TV[NUM=sg,SEM=<\\X x.X(\\ y.bite(x,y))>,TNS=pres] -> 'bites'\n",
    "TV[NUM=pl,SEM=<\\X x.X(\\ y.bite(x,y))>,TNS=pres] -> 'bite'\n",
    "DTV[NUM=sg,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'gives'\n",
    "DTV[NUM=pl,SEM=<\\Y X x.X(\\z.Y(\\y.give(x,y,z)))>,TNS=pres] -> 'give'\n",
    "\n",
    "P[+to] -> 'to'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your extension of this grammar here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcfg_string = fcfg_string_orginal + r\"\"\"\n",
    "## Your answers here\n",
    "# Det[???] -> ???\n",
    "# TV[???] -> ???\n",
    "# TV[???] -> ???\n",
    "# CONJ -> ???\n",
    "# NP[???] -> NP[???] CONJ NP[???]\n",
    "# N[???] -> ???\n",
    "# ADJ[???] -> ???\n",
    "# NP[???] -> Det[???] ADJ[???] Nom[???]\n",
    "\"\"\"\n",
    "\n",
    "# Load `fcfg_string` as a feature grammar:\n",
    "syntax = FeatureGrammar.fromstring(fcfg_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below without errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'no'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a4c523532b04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m'a brown cat chases a white dog'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpret_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyntax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msynrep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMarkdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'----'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/nltk/nltk/sem/util.py\u001b[0m in \u001b[0;36minterpret_sents\u001b[0;34m(inputs, grammar, semkey, trace)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m     83\u001b[0m     return [[(syn, root_semrep(syn, semkey)) for syn in syntrees]\n\u001b[0;32m---> 84\u001b[0;31m             for syntrees in parse_sents(inputs, grammar, trace=trace)]\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrammar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/nltk/nltk/sem/util.py\u001b[0m in \u001b[0;36mparse_sents\u001b[0;34m(inputs, grammar, trace)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use a tokenizer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msyntrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mparses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyntrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/nltk/nltk/parse/chart.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/nltk/nltk/parse/chart.py\u001b[0m in \u001b[0;36mchart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chart_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Applications/nltk/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             raise ValueError(\"Grammar does not cover some of the \"\n\u001b[0m\u001b[1;32m    631\u001b[0m                              \"input words: %r.\" % missing)\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'no'\"."
     ]
    }
   ],
   "source": [
    "# remove sentences if you couldn't find answer for them\n",
    "sentences = [\n",
    "    'no man gives a bone to a dog',\n",
    "    'a boy and a girl chased every dog',\n",
    "    'every dog chased a boy and a girl',\n",
    "    'a brown cat chases a white dog',\n",
    "]\n",
    "for results in nltk.interpret_sents(sentences, syntax):\n",
    "    for (synrep, semrep) in results:\n",
    "        display(Markdown('----'))\n",
    "        display_latex(semrep) # prints the SEM feature of a tree\n",
    "        display_tree(synrep) # show the parse tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with iPython which is also running behind Jupyter notebooks and you are changing grammars and want to rerun a new version without restarting you may find `nltk.data.clear_cache()` useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This part of the assignment has a total of 27 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
